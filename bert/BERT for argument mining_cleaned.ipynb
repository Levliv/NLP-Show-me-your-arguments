{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMGb0B9XLJStITqb3C3v6DE"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXpz9KgbZYdT",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1748175855506,
          "user_tz": -180,
          "elapsed": 2929,
          "user": {
            "displayName": "\u041b\u0435\u0432 \u041b\u0438\u0432\u0448\u0438\u0446",
            "userId": "08716300500381739347"
          }
        },
        "outputId": "7b6137f6-b965-43aa-f770-da3a6888e99b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import evaluate\n",
        "import wandb\n",
        "import random\n",
        "from datasets import Dataset\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from google.colab import userdata # hf token import from secrets"
      ],
      "metadata": {
        "id": "FF-aCJRzZg3O",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1748175872818,
          "user_tz": -180,
          "elapsed": 16735,
          "user": {
            "displayName": "\u041b\u0435\u0432 \u041b\u0438\u0432\u0448\u0438\u0446",
            "userId": "08716300500381739347"
          }
        }
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(mode='disabled')\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "Cdorim-9Zkhm",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1748175898271,
          "user_tz": -180,
          "elapsed": 134,
          "user": {
            "displayName": "\u041b\u0435\u0432 \u041b\u0438\u0432\u0448\u0438\u0446",
            "userId": "08716300500381739347"
          }
        }
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "transformers.set_seed(42)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "w6irS8d-ZvZ1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1748175882754,
          "user_tz": -180,
          "elapsed": 18,
          "user": {
            "displayName": "\u041b\u0435\u0432 \u041b\u0438\u0432\u0448\u0438\u0446",
            "userId": "08716300500381739347"
          }
        }
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "1lKVNVj6ZwiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
        "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
      ],
      "metadata": {
        "id": "TgAcGGClZy59",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1748175911035,
          "user_tz": -180,
          "elapsed": 12,
          "user": {
            "displayName": "\u041b\u0435\u0432 \u041b\u0438\u0432\u0448\u0438\u0446",
            "userId": "08716300500381739347"
          }
        }
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def distilbert(text_column, repository_id):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "    def preprocess_function(examples):\n",
        "        return tokenizer(examples[text_column], truncation=True)\n",
        "\n",
        "    # data\n",
        "    columns = [text_column] + ['label']\n",
        "    df_train = pd.read_csv(\"train.csv\")\n",
        "    df_train = df_train[columns]\n",
        "\n",
        "    df_test = pd.read_csv(\"test.csv\")\n",
        "    df_test = df_test[columns]\n",
        "\n",
        "    train_dataset = Dataset.from_pandas(df_train).train_test_split(test_size=0.15)\n",
        "    test_dataset = Dataset.from_pandas(df_test)\n",
        "\n",
        "    print(train_dataset)\n",
        "    print(test_dataset)\n",
        "\n",
        "    tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
        "    tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "    # load model\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        \"distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
        "    )\n",
        "\n",
        "    model = model.to(device)\n",
        "    print(model)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"my_awesome_model\",\n",
        "        learning_rate=2e-5,\n",
        "        per_device_train_batch_size=32,\n",
        "        per_device_eval_batch_size=32,\n",
        "        num_train_epochs=3,\n",
        "        eval_steps=20,\n",
        "        logging_steps=20,\n",
        "        weight_decay=0.01,\n",
        "        eval_strategy=\"steps\",\n",
        "        save_strategy=\"steps\",\n",
        "        load_best_model_at_end=True,\n",
        "        report_to=\"tensorboard\",\n",
        "        push_to_hub=True,\n",
        "        hub_strategy=\"every_save\",\n",
        "        hub_model_id=repository_id,\n",
        "        hub_token=userdata.get('hf'),\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_train_dataset['train'],\n",
        "        eval_dataset=tokenized_train_dataset['test'],\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    return trainer.evaluate(eval_dataset=tokenized_test_dataset)"
      ],
      "metadata": {
        "id": "sKX20DhRZ3cC",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1748175979089,
          "user_tz": -180,
          "elapsed": 20,
          "user": {
            "displayName": "\u041b\u0435\u0432 \u041b\u0438\u0432\u0448\u0438\u0446",
            "userId": "08716300500381739347"
          }
        }
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### distilbert for unmasked"
      ],
      "metadata": {
        "id": "DfzVYlKxaN_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(distilbert(\n",
        "    text_column='candidate',\n",
        "    repository_id = \"distilbert-base-uncased-0.0.1\"\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ead4b646eefb40baac3edc5b5fb408b9",
            "362647abb8304582852fd44ffd89c263",
            "607bb51d91fe4d31b9b9a7e6c06229a3",
            "93464cbc60cb4cddb835c816d419565d",
            "c51e163f85fa4b148ab4eae8495e09ac",
            "9459b1dd542c41cfbbd17baca27ffefb",
            "97bb7e3440194098b10bf571517cdb37",
            "d5432fa026714ce6aa58b5eef1ad798e",
            "6d473298686a46ec935077a1e2dddef0",
            "784a4c1a31ce42d8beb2ea22ba408af2",
            "aec7b127c9164245a858391d7a6995eb",
            "1708b083532149ebb2bdffcc4dee78ff",
            "66de9e6d1ecf40eab57bac71e8adf73f",
            "4bc37011b63a4b619f74e5be5b8fd0f7",
            "db6c289a570b4ae2a92331e353db2639",
            "3b4eb047f8de4417b8f4e7a080b4cd7c",
            "13e799d5ca7a46e8ab898151efe8599d",
            "7c601eac572140239b10b4a1691025ca",
            "4661df8620c74da79f8d76d71cf84fbb",
            "c8f8c93a63b44201bdf016ea2be3456a",
            "ec24368307884af79f97ab1000870d6b",
            "87a13f59dde24c0a8cacad7d398aa21c",
            "6cb332f4e32c48bb947a38e1b9dcb054",
            "4fadfb842f624e1abb07f635b9e16d14",
            "68feb46a4c094f34b1c44b43b1abe026",
            "7b9bd1d7c81e450bac80a7c4feb3b54f",
            "66b9c112fdb3473f926076a311148759",
            "4d2dbe14e3064dc0888b7b7a25433edc",
            "ab42dac9501e453fba9cdb690f789c31",
            "7bde9a4fe9f444fabc58f71da2da5128",
            "4c1bf2fd4c714d499639dd87c774d801",
            "9e3fc0cbdf7a46dc880069d102bb9d82",
            "42ba52f77547488f9dbcef9ac0b7f1ab",
            "0bfeee9ca97e4f04b3a11c68368f0aed",
            "1839c637f7004d9fa4bd4a9fdad56a03",
            "4d1d0e34177e443d958b938fac630e5e",
            "0e5462426ef742e280db4e4e637fcf12",
            "4087e40c3f6f476182f66e72d26263ed",
            "4f73039397954ee38ad729ce7e0b07c3",
            "35074ecc6ec74a3584edc3493e53be86",
            "3b2219a0f4a24a939cab62456fa13c47",
            "e997fc9803c249ab8073362e842ed068",
            "ece4b195256e44d2ac2fb64a5555fcc4",
            "32d692347ac14edebdd4e6a16c6b3566",
            "2a3da14fc99f411b9fd52aa963aafb50",
            "eee6cab3b4184ccd8cdb757d95a61455",
            "f9824500a2ea4e8aa65e3b4c800e168a",
            "bd386479345249fdb3781408c110d64f",
            "74ee46d133084249b08e8807e734f40a",
            "9741d84863f64d5e89267d89822b2eef",
            "b4c4e88f7f2d41e4a54fea8414488a6f",
            "b68f1956daf749a282b7c26350af8e75",
            "3e1b2ed331394819b619193a554c102d",
            "606d8a7f233840049caca730851cac24",
            "eb7740e0a1674850833937a4e7e010cf",
            "75152a6d599f4cd286891938d6c36b7e",
            "d334d3133f8c4c1a8c23887c45262860",
            "28ee6d30c888486287974fa4ed989788",
            "682d0f530bbd43028222dbd40b85982f",
            "d4dd39dd7306476ca02234235d15ed4e",
            "ea9fa6abf2e14fc6a7cc3b09b4e24ba8",
            "ccc9f95ff941491a8494fbec865f29c1",
            "af0d074217a740bf89bcdcd001cb174d",
            "a587f22ef0294780b4cd1840ce5f974c",
            "40f2e2aed6f84eb182fd181f287585a1",
            "aa56cceb255747f5b39ebc523a4309d9",
            "cbbc9b7d7a0347349303c490fd25b34b",
            "f1c013315a3a41ae9cd40f434f196474",
            "52c2ff18e9094d74a180da375d298d27",
            "bebc25f91c154bfb848f9aff177ea6ab",
            "c6902d1ee2ac47eda9f55457f7f06001",
            "f5d9f8b8aa9b420298ef55ec36ae2e91",
            "6291885b91c34a47b65d4c1b772cab69",
            "836739db09164b7c8c1dc0ac0b3cd058",
            "25a6626c4432471991de94fc1407635c",
            "9906e753a53448579c576046acb03768",
            "72ccd9fa110a4d4cba1c6bd374dd450e",
            "1444ff599b08406cb1467c29d626e5e7",
            "9bbc494613f248198336c1f0adbb6898",
            "ab83dcd5fddf454180b74849483d3267",
            "f5a743974bc84703be8be27d034c1f57",
            "e119dbcda5544918ae9625ec20980a31",
            "e7d6e51bbdd842989f482ecc0187b8a9",
            "5e066e9487a14ea8914a92870a90bf8b",
            "7650d65522b9454f976c9434a4d007b4",
            "63278431eab54f5fbcb1946f1125e63f",
            "df989fde39124e45aa24a9b2c8b9417a",
            "c9d6ad87bd284d3bacb00e3fa5a2db50"
          ]
        },
        "id": "e--ab0mvZ4gD",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1748176088864,
          "user_tz": -180,
          "elapsed": 71904,
          "user": {
            "displayName": "\u041b\u0435\u0432 \u041b\u0438\u0432\u0448\u0438\u0446",
            "userId": "08716300500381739347"
          }
        },
        "outputId": "d082fad3-56f9-4110-972a-0639e999c5b2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ead4b646eefb40baac3edc5b5fb408b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1708b083532149ebb2bdffcc4dee78ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cb332f4e32c48bb947a38e1b9dcb054"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bfeee9ca97e4f04b3a11c68368f0aed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['candidate', 'label'],\n",
            "        num_rows: 3455\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['candidate', 'label'],\n",
            "        num_rows: 610\n",
            "    })\n",
            "})\n",
            "Dataset({\n",
            "    features: ['candidate', 'label'],\n",
            "    num_rows: 1718\n",
            "})\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3455 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a3da14fc99f411b9fd52aa963aafb50"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/610 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75152a6d599f4cd286891938d6c36b7e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1718 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cbbc9b7d7a0347349303c490fd25b34b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1444ff599b08406cb1467c29d626e5e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBertForSequenceClassification(\n",
            "  (distilbert): DistilBertModel(\n",
            "    (embeddings): Embeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer): Transformer(\n",
            "      (layer): ModuleList(\n",
            "        (0-5): 6 x TransformerBlock(\n",
            "          (attention): DistilBertSdpaAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (activation): GELUActivation()\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-032c1d0ffb55>:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='324' max='324' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [324/324 00:47, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.664700</td>\n",
              "      <td>0.638682</td>\n",
              "      <td>0.626230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.589900</td>\n",
              "      <td>0.573101</td>\n",
              "      <td>0.686885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.529200</td>\n",
              "      <td>0.525568</td>\n",
              "      <td>0.711475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.485700</td>\n",
              "      <td>0.522061</td>\n",
              "      <td>0.714754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.484900</td>\n",
              "      <td>0.517077</td>\n",
              "      <td>0.727869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.449500</td>\n",
              "      <td>0.495654</td>\n",
              "      <td>0.737705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.398400</td>\n",
              "      <td>0.473347</td>\n",
              "      <td>0.750820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.415300</td>\n",
              "      <td>0.489255</td>\n",
              "      <td>0.752459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.427200</td>\n",
              "      <td>0.466593</td>\n",
              "      <td>0.744262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.377900</td>\n",
              "      <td>0.470190</td>\n",
              "      <td>0.768852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.365700</td>\n",
              "      <td>0.466162</td>\n",
              "      <td>0.770492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.326100</td>\n",
              "      <td>0.469820</td>\n",
              "      <td>0.763934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.326200</td>\n",
              "      <td>0.479249</td>\n",
              "      <td>0.763934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.336300</td>\n",
              "      <td>0.485160</td>\n",
              "      <td>0.772131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.295200</td>\n",
              "      <td>0.480104</td>\n",
              "      <td>0.778689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.314000</td>\n",
              "      <td>0.477982</td>\n",
              "      <td>0.768852</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [54/54 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.4886702001094818, 'eval_accuracy': 0.7770663562281723, 'eval_runtime': 1.8129, 'eval_samples_per_second': 947.67, 'eval_steps_per_second': 29.787, 'epoch': 3.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### distilbert for masked"
      ],
      "metadata": {
        "id": "DZSsSYA2aXcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(distilbert(\n",
        "    text_column='candidate masked',\n",
        "    repository_id = \"distilbert-base-uncased-0.0.1\"\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2205f96720a846b8ab44d56be2016643",
            "e4aad11e16ce4cb2be01232554975996",
            "885de5c19c914373ab3e501648601886",
            "4753e5e8748d48c9966f7948db7f2704",
            "092494a8aac949b39ce472c56fd605a0",
            "c48dbe9575ba4d22a9450125ee2b6ff2",
            "84208dc5e40c4d4fbaae0b08c78df64b",
            "d2eec5f15cff4348b80cd74bea747670",
            "e034201208b540438673f077455613b8",
            "a0b1776f7cce46c0941a67b52dd05ffc",
            "99b6d6dc741944409dd3a0faed97daf6",
            "49d97519b7594d4ab4786e4b7c64b6ae",
            "6028883c95d8427292a9b9d77ec61ba4",
            "58044a3b13c74faf94270cff580ffcd1",
            "dcca3d54afdc4ee98991f9b3f503a7c4",
            "88cfcc731ac441cfae1adeb105a71deb",
            "922510f4389f43e595b29885ad50c5fe",
            "c1b07f10d29f4912af924be47b533f14",
            "0a733642a71b438c86579c06914dab17",
            "96c4b6c823964fd6b754d25d6e94e494",
            "f38c803b3e88426da078aae3a1aa7017",
            "2fc80a3de58c47a28d7fabcb906d0674",
            "d015abe5a12b4c17b9045e9bf4214c68",
            "92370b2228e847bba5b45a24d0db3bff",
            "8fd6ca39ee744d0ba4bdf3391e054c13",
            "8a01e086bfbb491daf9cd89b1f77a78d",
            "9c7f3c37d9264d868c330c6b35ad5cfd",
            "2f411fdca03e4a64a37916f9156b2fa4",
            "94ae79e6589747b28b3f9d6f044c0c99",
            "e4aeabe4596e4983b5cad9a2780adb0a",
            "d4f7d16e12e14994b16a32922a9ecf16",
            "9e702afdc3714937a5c87c4fccd2c94f",
            "497074231a0e40cba6457b503d5a1744"
          ]
        },
        "id": "4-4pS93BaRTS",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1748176147239,
          "user_tz": -180,
          "elapsed": 58333,
          "user": {
            "displayName": "\u041b\u0435\u0432 \u041b\u0438\u0432\u0448\u0438\u0446",
            "userId": "08716300500381739347"
          }
        },
        "outputId": "2140f5aa-33b7-47e2-f98f-8fa14656e39f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['candidate masked', 'label'],\n",
            "        num_rows: 3455\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['candidate masked', 'label'],\n",
            "        num_rows: 610\n",
            "    })\n",
            "})\n",
            "Dataset({\n",
            "    features: ['candidate masked', 'label'],\n",
            "    num_rows: 1718\n",
            "})\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3455 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2205f96720a846b8ab44d56be2016643"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/610 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49d97519b7594d4ab4786e4b7c64b6ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1718 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d015abe5a12b4c17b9045e9bf4214c68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBertForSequenceClassification(\n",
            "  (distilbert): DistilBertModel(\n",
            "    (embeddings): Embeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer): Transformer(\n",
            "      (layer): ModuleList(\n",
            "        (0-5): 6 x TransformerBlock(\n",
            "          (attention): DistilBertSdpaAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (activation): GELUActivation()\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-032c1d0ffb55>:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='324' max='324' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [324/324 00:49, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.660900</td>\n",
              "      <td>0.628467</td>\n",
              "      <td>0.626230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.581700</td>\n",
              "      <td>0.559814</td>\n",
              "      <td>0.704918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.550500</td>\n",
              "      <td>0.536554</td>\n",
              "      <td>0.726230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.514200</td>\n",
              "      <td>0.530576</td>\n",
              "      <td>0.721311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.511300</td>\n",
              "      <td>0.529294</td>\n",
              "      <td>0.722951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.451600</td>\n",
              "      <td>0.498706</td>\n",
              "      <td>0.739344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.409700</td>\n",
              "      <td>0.478102</td>\n",
              "      <td>0.767213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.428400</td>\n",
              "      <td>0.517635</td>\n",
              "      <td>0.711475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.448600</td>\n",
              "      <td>0.482840</td>\n",
              "      <td>0.760656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.393000</td>\n",
              "      <td>0.480264</td>\n",
              "      <td>0.762295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.400200</td>\n",
              "      <td>0.478897</td>\n",
              "      <td>0.768852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.346600</td>\n",
              "      <td>0.482315</td>\n",
              "      <td>0.762295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.347600</td>\n",
              "      <td>0.485251</td>\n",
              "      <td>0.777049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.354200</td>\n",
              "      <td>0.483152</td>\n",
              "      <td>0.777049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.332300</td>\n",
              "      <td>0.484626</td>\n",
              "      <td>0.775410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.329500</td>\n",
              "      <td>0.483633</td>\n",
              "      <td>0.773770</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [54/54 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.4758956730365753, 'eval_accuracy': 0.779976717112922, 'eval_runtime': 1.853, 'eval_samples_per_second': 927.127, 'eval_steps_per_second': 29.141, 'epoch': 3.0}\n"
          ]
        }
      ]
    }
  ]
}